---
interact_link: content/1-useage.ipynb
kernel_name: python3
kernel_path: content
has_widgets: false
title: |-
  Usage
pagenum: 2
prev_page:
  url: /0-install.html
next_page:
  url: /2-tuning.html
suffix: .ipynb
search: scipy distribution regression set returns distributions ngboost used logscore stats classification implemented scores reference org argument score crpscore class survival k p wikipedia parameters normal scale docs doc generated html lognormal exponential constructor appropriate default also bernoulli base points standard test those support through ngbregressor passing dist prediction methods objects predict regressor preddist object conditional xi supports right censored any analysis event censoring fit kcategorical en wiki ngbclassifier using sklearn log specified usage well start probabilistic example boston housing dataset getting estimated distributional easy predicted mean deviation five observations variety broken into infinite finite loc norm s lognorm expon point

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Usage</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We'll start with a probabilistic regression example on the Boston housing dataset:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ngboost</span> <span class="k">import</span> <span class="n">NGBRegressor</span>

<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">mean_squared_error</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">ngb</span> <span class="o">=</span> <span class="n">NGBRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_preds</span> <span class="o">=</span> <span class="n">ngb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">Y_dists</span> <span class="o">=</span> <span class="n">ngb</span><span class="o">.</span><span class="n">pred_dist</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># test Mean Squared Error</span>
<span class="n">test_MSE</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">Y_preds</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test MSE&#39;</span><span class="p">,</span> <span class="n">test_MSE</span><span class="p">)</span>

<span class="c1"># test Negative Log Likelihood</span>
<span class="n">test_NLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">Y_dists</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test NLL&#39;</span><span class="p">,</span> <span class="n">test_NLL</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[iter 0] loss=3.6486 val_loss=0.0000 scale=0.5000 norm=3.4791
[iter 100] loss=3.1043 val_loss=0.0000 scale=1.0000 norm=3.9358
[iter 200] loss=2.4762 val_loss=0.0000 scale=2.0000 norm=4.1521
[iter 300] loss=2.0484 val_loss=0.0000 scale=1.0000 norm=1.6249
[iter 400] loss=1.8610 val_loss=0.0000 scale=1.0000 norm=1.4547
Test MSE 7.719871354323341
Test NLL 2.8867507325340243
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Getting the estimated distributional parameters at a set of points is easy. This returns the predicted mean and standard deviation of the first five observations in the test set:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Y_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;loc&#39;: array([15.71909047, 19.51384116, 19.24509285, 17.8645122 , 24.31325397]),
 &#39;scale&#39;: array([1.48748154, 1.37673424, 1.67090687, 1.63854999, 1.52513887])}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Distributions">Distributions<a class="anchor-link" href="#Distributions"> </a></h2><p>NGBoost can be used with a variety of distributions, broken down into those for regression (support on an infinite set) and those for classification (support on a finite set).</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Regression-Distributions">Regression Distributions<a class="anchor-link" href="#Regression-Distributions"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>Distribution</th>
<th>Parameters</th>
<th>Implemented Scores</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Normal</code></td>
<td><code>loc</code>, <code>scale</code></td>
<td><code>LogScore</code>, <code>CRPScore</code></td>
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html"><code>scipy.stats</code> normal</a></td>
</tr>
<tr>
<td><code>LogNormal</code></td>
<td><code>s</code>, <code>scale</code></td>
<td><code>LogScore</code>, <code>CRPScore</code></td>
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html"><code>scipy.stats</code> lognormal</a></td>
</tr>
<tr>
<td><code>Exponential</code></td>
<td><code>scale</code></td>
<td><code>LogScore</code>, <code>CRPScore</code></td>
<td><a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html"><code>scipy.stats</code> exponential</a></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Regression distributions can be used through the <code>NGBRegressor()</code> constructor by passing the appropriate class as the <code>Dist</code> argument. <code>Normal</code> is the default.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ngboost.distns</span> <span class="k">import</span> <span class="n">Exponential</span><span class="p">,</span> <span class="n">Normal</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_reg_train</span><span class="p">,</span> <span class="n">X_reg_test</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">,</span> <span class="n">Y_reg_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">ngb_norm</span> <span class="o">=</span> <span class="n">NGBRegressor</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">Normal</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reg_train</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">)</span>
<span class="n">ngb_exp</span> <span class="o">=</span> <span class="n">NGBRegressor</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">Exponential</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reg_train</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are two prediction methods for <code>NGBRegressor</code> objects: <code>predict()</code>, which returns point predictions as one would expect from a standard regressor, and <code>pred_dist()</code>, which returns a distribution object representing the conditional distribution of $Y|X=x_i$ at the points $x_i$ in the test set.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_norm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_reg_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([21.25837828,  9.88964092, 23.01338315, 10.89576892, 16.12806237])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_exp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_reg_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([20.94799589,  9.38317525, 22.88445968, 10.33327537, 14.83048942])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_exp</span><span class="o">.</span><span class="n">pred_dist</span><span class="p">(</span><span class="n">X_reg_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;scale&#39;: array([20.94799589,  9.38317525, 22.88445968, 10.33327537, 14.83048942])}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Survival-Regression">Survival Regression<a class="anchor-link" href="#Survival-Regression"> </a></h4>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>NGBoost supports analyses of right-censored data. Any distribution that can be used for regression in NGBoost can also be used for survival analysis in theory, but this requires the implementation of the right-censored version of the appropriate score. At the moment, <code>LogNormal</code> and <code>Exponential</code> have these scores implemented. To do survival analysis, use <code>NGBSurvival</code> and pass both the time-to-event (or censoring) and event indicator vectors to  <code>fit()</code>:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">ngboost</span> <span class="k">import</span> <span class="n">NGBSurvival</span>
<span class="kn">from</span> <span class="nn">ngboost.distns</span> <span class="k">import</span> <span class="n">LogNormal</span>

<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_surv_train</span><span class="p">,</span> <span class="n">X_surv_test</span><span class="p">,</span> <span class="n">Y_surv_train</span><span class="p">,</span> <span class="n">Y_surv_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># introduce administrative censoring to simulate survival data</span>
<span class="n">T_surv_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span> <span class="c1"># time of an event or censoring</span>
<span class="n">E_surv_train</span> <span class="o">=</span> <span class="n">Y_train</span> <span class="o">&gt;</span> <span class="mi">30</span> <span class="c1"># 1 if T[i] is the time of an event, 0 if it&#39;s a time of censoring</span>

<span class="n">ngb</span> <span class="o">=</span> <span class="n">NGBSurvival</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">LogNormal</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_surv_train</span><span class="p">,</span> <span class="n">T_surv_train</span><span class="p">,</span> <span class="n">E_surv_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[iter 0] loss=1.2960 val_loss=0.0000 scale=8.0000 norm=4.8495
[iter 100] loss=0.6339 val_loss=0.0000 scale=2.0000 norm=0.7358
[iter 200] loss=0.3803 val_loss=0.0000 scale=4.0000 norm=0.9619
[iter 300] loss=0.2276 val_loss=0.0000 scale=8.0000 norm=0.9190
[iter 400] loss=0.1178 val_loss=0.0000 scale=4.0000 norm=0.3496
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The scores currently implemented assume that the censoring is independent of survival, conditional on the observed predictors.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Classification-Distributions">Classification Distributions<a class="anchor-link" href="#Classification-Distributions"> </a></h3>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<table>
<thead><tr>
<th>Distribution</th>
<th>Parameters</th>
<th>Implemented Scores</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>k_categorical(K)</code></td>
<td><code>p0</code>, <code>p1</code>... <code>p{K-1}</code></td>
<td><code>LogScore</code></td>
<td><a href="https://en.wikipedia.org/wiki/Categorical_distribution">Categorical distribution on Wikipedia</a></td>
</tr>
<tr>
<td><code>Bernoulli</code></td>
<td><code>p</code></td>
<td><code>LogScore</code></td>
<td><a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution on Wikipedia</a></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Classification distributions can be used through the <code>NGBClassifier()</code> constructor by passing the appropriate class as the <code>Dist</code> argument. <code>Bernoulli</code> is the default and is equivalent to <code>k_categorical(2)</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ngboost</span> <span class="k">import</span> <span class="n">NGBClassifier</span>
<span class="kn">from</span> <span class="nn">ngboost.distns</span> <span class="k">import</span> <span class="n">k_categorical</span><span class="p">,</span> <span class="n">Bernoulli</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_breast_cancer</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">15</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># artificially make this a 3-class problem instead of a 2-class problem</span>
<span class="n">X_cls_train</span><span class="p">,</span> <span class="n">X_cls_test</span><span class="p">,</span> <span class="n">Y_cls_train</span><span class="p">,</span> <span class="n">Y_cls_test</span>  <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">ngb_cat</span> <span class="o">=</span> <span class="n">NGBClassifier</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">k_categorical</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># tell ngboost that there are 3 possible outcomes</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ngb_cat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cls_train</span><span class="p">,</span> <span class="n">Y_cls_train</span><span class="p">)</span> <span class="c1"># Y should have only 3 values: {0,1,2}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When using NGBoost for classification, the outcome vector <code>Y</code> must consist only of integers from 0 to K-1, where K is the total number of classes. This is consistent with the classification standards in sklearn.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>NGBClassifier</code> objects have three prediction methods: <code>predict()</code> returns the most likely class, <code>predict_proba()</code> returns the class probabilities, and <code>pred_dist()</code> returns the distribution object.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_cat</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_cls_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1, 1, 1, 0, 1])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_cat</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_cls_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([[3.53080012e-03, 9.96242905e-01, 2.26294536e-04],
       [6.59565268e-03, 9.93168490e-01, 2.35857004e-04],
       [3.53080012e-03, 9.96242905e-01, 2.26294536e-04],
       [9.92981053e-01, 6.07012737e-03, 9.48819937e-04],
       [3.53080012e-03, 9.96242905e-01, 2.26294536e-04]])</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb_cat</span><span class="o">.</span><span class="n">pred_dist</span><span class="p">(</span><span class="n">X_cls_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">params</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;p0&#39;: array([0.0035308 , 0.00659565, 0.0035308 , 0.99298105, 0.0035308 ]),
 &#39;p1&#39;: array([0.99624291, 0.99316849, 0.99624291, 0.00607013, 0.99624291]),
 &#39;p2&#39;: array([0.00022629, 0.00023586, 0.00022629, 0.00094882, 0.00022629])}</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Scores">Scores<a class="anchor-link" href="#Scores"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>NGBoost supports the log score (<code>LogScore</code>, also known as negative log-likelihood) and CRPS (<code>CRPScore</code>), although each score may not be implemented for each distribution. The score is specified by the <code>Score</code> argument in the constructor.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_output">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ngboost.scores</span> <span class="k">import</span> <span class="n">LogScore</span><span class="p">,</span> <span class="n">CRPScore</span>

<span class="n">NGBRegressor</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">Exponential</span><span class="p">,</span> <span class="n">Score</span><span class="o">=</span><span class="n">CRPScore</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reg_train</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">)</span>
<span class="n">NGBClassifier</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">k_categorical</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="n">Score</span><span class="o">=</span><span class="n">LogScore</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cls_train</span><span class="p">,</span> <span class="n">Y_cls_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NGBClassifier(Base=DecisionTreeRegressor(criterion=&#39;friedman_mse&#39;, max_depth=3,
                                         max_features=None, max_leaf_nodes=None,
                                         min_impurity_decrease=0.0,
                                         min_impurity_split=None,
                                         min_samples_leaf=1,
                                         min_samples_split=2,
                                         min_weight_fraction_leaf=0.0,
                                         presort=False, random_state=None,
                                         splitter=&#39;best&#39;),
              Dist=&lt;class &#39;ngboost.distns.categorical.k_categorical.&lt;locals&gt;.Categorical&#39;&gt;,
              Score=&lt;class &#39;ngboost.scores.LogScore&#39;&gt;, col_sample=1.0,
              learning_rate=0.01, minibatch_frac=1.0, n_estimators=500,
              natural_gradient=True,
              random_state=RandomState(MT19937) at 0x117AF2D10, tol=0.0001,
              verbose=False, verbose_eval=100)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Base-Learners">Base Learners<a class="anchor-link" href="#Base-Learners"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>NGBoost can be used with any sklearn regressor as the base learner, specified with the <code>Base</code> argument. The default is a depth-3 regression tree.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_output">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="k">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;friedman_mse&#39;</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">NGBSurvival</span><span class="p">(</span><span class="n">Dist</span><span class="o">=</span><span class="n">Exponential</span><span class="p">,</span> <span class="n">Score</span><span class="o">=</span><span class="n">CRPScore</span><span class="p">,</span> <span class="n">Base</span><span class="o">=</span><span class="n">learner</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_surv_train</span><span class="p">,</span> <span class="n">T_surv_train</span><span class="p">,</span> <span class="n">E_surv_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NGBSurvival(Base=DecisionTreeRegressor(criterion=&#39;friedman_mse&#39;, max_depth=5,
                                       max_features=None, max_leaf_nodes=None,
                                       min_impurity_decrease=0.0,
                                       min_impurity_split=None,
                                       min_samples_leaf=1, min_samples_split=2,
                                       min_weight_fraction_leaf=0.0,
                                       presort=False, random_state=None,
                                       splitter=&#39;best&#39;),
            Dist=&lt;class &#39;ngboost.api.NGBSurvival.__init__.&lt;locals&gt;.SurvivalDistn&#39;&gt;,
            Score=&lt;class &#39;ngboost.scores.CRPScore&#39;&gt;, col_sample=1.0,
            learning_rate=0.01, minibatch_frac=1.0, n_estimators=500,
            natural_gradient=True,
            random_state=RandomState(MT19937) at 0x117AF2D10, tol=0.0001,
            verbose=False, verbose_eval=100)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Other-Arguments">Other Arguments<a class="anchor-link" href="#Other-Arguments"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The learning rate, number of estimators, minibatch fraction, and column subsampling are also easily adjusted:</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_output">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb</span> <span class="o">=</span> <span class="n">NGBRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
             <span class="n">minibatch_frac</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">col_sample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ngb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reg_train</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[iter 0] loss=3.6328 val_loss=0.0000 scale=0.5000 norm=3.3554
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NGBRegressor(Base=DecisionTreeRegressor(criterion=&#39;friedman_mse&#39;, max_depth=3,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_impurity_split=None,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        presort=False, random_state=None,
                                        splitter=&#39;best&#39;),
             Dist=&lt;class &#39;ngboost.distns.normal.Normal&#39;&gt;,
             Score=&lt;class &#39;ngboost.scores.LogScore&#39;&gt;, col_sample=0.5,
             learning_rate=0.01, minibatch_frac=0.5, n_estimators=100,
             natural_gradient=True,
             random_state=RandomState(MT19937) at 0x117AF2D10, tol=0.0001,
             verbose=True, verbose_eval=100)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Sample weights (for training) are set using the <code>sample_weight</code> argument to <code>fit</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell tag_hide_output">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ngb</span> <span class="o">=</span> <span class="n">NGBRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
             <span class="n">minibatch_frac</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">col_sample</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">Y_reg_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ngb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_reg_train</span><span class="p">,</span> <span class="n">Y_reg_train</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[iter 0] loss=3.6257 val_loss=0.0000 scale=1.0000 norm=6.6551
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NGBRegressor(Base=DecisionTreeRegressor(criterion=&#39;friedman_mse&#39;, max_depth=3,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_impurity_split=None,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        presort=False, random_state=None,
                                        splitter=&#39;best&#39;),
             Dist=&lt;class &#39;ngboost.distns.normal.Normal&#39;&gt;,
             Score=&lt;class &#39;ngboost.scores.LogScore&#39;&gt;, col_sample=0.5,
             learning_rate=0.01, minibatch_frac=0.5, n_estimators=100,
             natural_gradient=True,
             random_state=RandomState(MT19937) at 0x117AF2D10, tol=0.0001,
             verbose=True, verbose_eval=100)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    